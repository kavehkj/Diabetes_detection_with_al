# 🩺 Diabetes Prediction Using Machine Learning & Deep Learning

A comprehensive Python project that applies several machine‑learning and deep‑learning algorithms to predict **diabetes** from routine medical data.  

---

## 📊 Dataset

**Source:** [Kaggle – Diabetes Prediction Dataset](https://www.kaggle.com/datasets/marshalpatel3558/diabetes-prediction-dataset-legit-dataset/data)

Main features

| Column (sample) | Description (abridged) |
|-----------------|------------------------|
| `age`           | Patient age (years)   |
| `bmi`           | Body‑Mass Index       |
| `hypertension`  | 1 = yes, 0 = no       |
| `heart_disease` | 1 = yes, 0 = no       |
| `smoking_history` | categorical levels  |
| `HbA1c_level`   | Glycated haemoglobin |
| `blood_glucose_level` | Glucose (mg/dL)|
| `diabetes`      | **Target** (1 = positive, 0 = negative)|

---


## 🧠 Models & Accuracies

| Model                          | Accuracy |
|--------------------------------|----------|
| Logistic Regression            | **93.5 %** |
| SVM (RBF kernel) + GridSearch  | **96.0 %** |
| **XGBoost**                    | **99.0 %** |
| **Random Forest**              | **99.5 %** |
| Deep ANN (2 hidden layers)     | **95.0 %** |

🏆 *Random Forest* delivered the top score, narrowly ahead of XGBoost.

---

## 📈 Visualizations

* **Correlation heatmaps** – spot multicollinearity  
* **Feature distributions** – understand class imbalance  
* **ROC curves** – compare true‑positive vs. false‑positive rates per model  
* **Confusion matrices** – inspect model‑specific misclassifications  

All plots reside in **`results/`** and are auto‑generated by the notebook.

---

## ✅ Key Findings

* **Random Forest** and **XGBoost** both surpassed **99 % accuracy**.
* Hyper‑parameter tuning via **GridSearchCV** notably boosted SVM performance.
* The **Deep ANN** (ReLU×2 → Sigmoid) attained **95 % accuracy** with minimal over‑fitting.

---

## 🔨 How to Run

```bash
git clone https://github.com/kavehkj/Diabetes_detection_with_al.git
